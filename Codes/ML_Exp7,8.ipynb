{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 7,8:\n",
        "To implement perceptron and backpropogation on non-binary inputs."
      ],
      "metadata": {
        "id": "FTmqfE6KsAfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEkH9URTr531"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, inputs: list, output: int):\n",
        "    super(Perceptron, self).__init__()\n",
        "    self.inputs = inputs\n",
        "    self.output = output\n",
        "    self.weights = [random.randrange(1) for i in range(len(inputs))]\n",
        "\n",
        "  def forward_backward_pass(self):\n",
        "    weighted_sum = sum([x*y for x,y in zip(self.inputs, self.weights)])\n",
        "    # activation = 0 if weighted_sum < 0 else 1\n",
        "    activation = 1 / 1 + math.exp(-weighted_sum)\n",
        "    output_x = activation\n",
        "    error = 1/2 * (self.output - output_x) ** 2\n",
        "\n",
        "    # Backward Pass (Backpropogation)\n",
        "    new_weights = []\n",
        "    delta_w1 = (output_x * self.output) * \\\n",
        "      activation * (1 - activation) * self.inputs[0]\n",
        "    delta_w2 = (output_x * self.output) * \\\n",
        "      activation * (1 - activation) * self.inputs[1]\n",
        "    new_w1 = self.weights[0] - delta_w1\n",
        "    new_w2 = self.weights[1] - delta_w2\n",
        "    new_weights.append(new_w1)\n",
        "    new_weights.append(new_w2)\n",
        "    new_weighted_sum = sum([x*y for x,y in zip(self.inputs, new_weights)])\n",
        "\n",
        "    new_activation = 1 / 1 + math.exp(-new_weighted_sum)\n",
        "    new_output_x = new_activation\n",
        "    new_error = 1/2 * (self.output - new_output_x) ** 2\n",
        "    return error, new_error"
      ],
      "metadata": {
        "id": "U3r8qCbKth7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [0.3, 0.7]\n",
        "output = 1\n",
        "\n",
        "error_fp, error_bp = Perceptron(inputs, output).forward_backward_pass()"
      ],
      "metadata": {
        "id": "k6cJTwHwtzdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Forward pass error is: {error_fp}\")\n",
        "print(f\"After Backpropagation error is: {error_bp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJNsnI46vHzU",
        "outputId": "f65fdd6c-f20e-4c84-afd8-20a86d5c03e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward pass error is: 0.5\n",
            "After Backpropagation error is: 0.004828848813768884\n"
          ]
        }
      ]
    }
  ]
}